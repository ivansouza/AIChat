<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>AI Local Mobile - V9</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <style>
        body { 
            height: 100dvh; 
            overscroll-behavior-y: none; 
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: #111827;
        }
        .no-scrollbar::-webkit-scrollbar { display: none; }
        .message-bubble { animation: slideIn 0.25s ease-out forwards; opacity: 0; transform: translateY(10px); }
        .safe-bottom { padding-bottom: env(safe-area-inset-bottom, 20px); }
        
        @keyframes slideIn { to { opacity: 1; transform: translateY(0); } }
        
        .typing-dot { animation: bounce 1.4s infinite ease-in-out both; background-color: #60a5fa; }
        .typing-dot:nth-child(1) { animation-delay: -0.32s; }
        .typing-dot:nth-child(2) { animation-delay: -0.16s; }
        @keyframes bounce { 0%, 80%, 100% { transform: scale(0); } 40% { transform: scale(1); } }
    </style>
</head>
<body class="text-gray-100 flex flex-col overflow-hidden">

    <!-- Setup Screen -->
    <div id="setup-screen" class="absolute inset-0 z-50 bg-[#111827] flex flex-col items-center justify-center p-6 transition-opacity duration-500 overflow-y-auto">
        <div class="w-full max-w-md space-y-6 text-center">
            
            <div class="flex flex-col items-center">
                <div class="w-20 h-20 bg-blue-600 rounded-2xl flex items-center justify-center shadow-xl shadow-blue-900/40 mb-5 relative">
                    <i data-lucide="zap" class="w-10 h-10 text-white"></i>
                    <span class="absolute -bottom-2 -right-2 bg-green-500 text-black text-[10px] font-bold px-2 py-0.5 rounded-full border-2 border-[#111827]">V9</span>
                </div>
                <h1 class="text-3xl font-bold text-white tracking-tight">Llama 3.2 Lite</h1>
                <p class="text-blue-300/80 text-sm mt-2">Rápido • Leve • Universal</p>
            </div>

            <!-- Aviso de Memória -->
            <div class="bg-yellow-900/20 border border-yellow-700/50 p-3 rounded-lg flex gap-3 text-left">
                <i data-lucide="alert-triangle" class="w-5 h-5 text-yellow-500 flex-none mt-0.5"></i>
                <p class="text-xs text-yellow-200/90 leading-relaxed">
                    <strong>Dica Importante:</strong> Se o navegador travou antes, feche outras abas para liberar memória RAM.
                </p>
            </div>

            <div class="bg-gray-800/50 p-4 rounded-xl border border-gray-700/50 text-left">
                <label class="text-[10px] font-bold text-gray-400 uppercase tracking-wider mb-2 block">Modelo Otimizado</label>
                <!-- Forçamos o Llama 3.2 1B em modo float32 (Universal) -->
                <!-- Este é o equilíbrio perfeito entre inteligência e compatibilidade -->
                <select id="model-select" class="w-full bg-gray-900 text-white text-sm p-3 rounded-lg border border-gray-700 focus:border-blue-500 outline-none">
                    <option value="Llama-3.2-1B-Instruct-q4f32_1-MLC" selected>Llama 3.2 1B (Universal/Smart)</option>
                </select>
                <div id="gpu-tag" class="mt-2 flex items-center gap-2 text-[10px] text-gray-500">
                    <div class="w-1.5 h-1.5 rounded-full bg-gray-600"></div>
                    Verificando GPU...
                </div>
            </div>

            <div id="progress-area" class="hidden w-full bg-gray-800/50 p-4 rounded-xl border border-gray-700/50">
                <div class="flex justify-between text-xs font-bold text-blue-400 mb-2">
                    <span id="progress-phase">Preparando...</span>
                    <span id="progress-percent">0%</span>
                </div>
                <div class="w-full bg-gray-900/50 rounded-full h-1.5 mb-3 overflow-hidden">
                    <div id="progress-bar" class="bg-blue-500 h-full transition-all duration-300 rounded-full" style="width: 0%"></div>
                </div>
                <div id="progress-log" class="text-[10px] text-gray-500 font-mono text-left h-8 overflow-hidden leading-tight opacity-60"></div>
            </div>

            <button id="btn-load" class="w-full py-4 bg-blue-600 hover:bg-blue-500 text-white font-bold rounded-xl shadow-lg shadow-blue-900/20 flex items-center justify-center gap-2 disabled:opacity-50 disabled:cursor-not-allowed transition-all active:scale-95">
                <span>Iniciar Chat</span>
                <i data-lucide="arrow-right" class="w-4 h-4"></i>
            </button>

            <div id="error-msg" class="hidden p-4 text-sm text-red-200 bg-red-900/20 border border-red-800/50 rounded-xl text-left break-words"></div>
        </div>
    </div>

    <!-- Chat Interface -->
    <div id="chat-interface" class="flex flex-col h-full opacity-0 pointer-events-none transition-opacity duration-500 relative bg-[#111827]">
        <header class="flex-none bg-[#111827]/90 backdrop-blur border-b border-gray-800 p-4 flex items-center justify-between z-10 sticky top-0">
            <div class="flex items-center gap-3">
                <div class="w-8 h-8 bg-blue-600 rounded-lg flex items-center justify-center text-white shadow-lg shadow-blue-900/30">
                    <i data-lucide="bot" class="w-5 h-5"></i>
                </div>
                <div>
                    <h2 class="font-bold text-gray-100 text-sm">Llama 3.2</h2>
                    <p class="text-[10px] text-green-400 flex items-center gap-1.5 font-medium">
                        <span class="w-1.5 h-1.5 rounded-full bg-green-500 animate-pulse"></span> Online (f32)
                    </p>
                </div>
            </div>
            <button onclick="window.location.reload()" class="p-2 text-gray-400 hover:text-white hover:bg-gray-800 rounded-full transition-colors">
                <i data-lucide="refresh-cw" class="w-4 h-4"></i>
            </button>
        </header>

        <main id="messages-container" class="flex-1 overflow-y-auto p-4 space-y-6 no-scrollbar pb-4"></main>

        <div id="typing-indicator" class="hidden px-6 py-2">
            <div class="flex gap-1 bg-gray-800/50 w-fit px-3 py-2.5 rounded-2xl rounded-bl-none border border-gray-700/30">
                <div class="w-1.5 h-1.5 rounded-full typing-dot"></div>
                <div class="w-1.5 h-1.5 rounded-full typing-dot"></div>
                <div class="w-1.5 h-1.5 rounded-full typing-dot"></div>
            </div>
        </div>

        <footer class="flex-none bg-[#111827] border-t border-gray-800 safe-bottom">
            <form id="chat-form" class="flex gap-2 p-3 items-end">
                <div class="flex-1 relative">
                    <textarea id="user-input" rows="1" placeholder="Digite sua mensagem..." class="w-full bg-gray-800 text-white border border-gray-700 rounded-2xl px-4 py-3.5 focus:outline-none focus:border-blue-500/50 focus:bg-gray-800/80 transition-all resize-none max-h-32 leading-normal placeholder-gray-500" style="min-height: 48px;"></textarea>
                </div>
                <button type="submit" id="send-btn" disabled class="bg-blue-600 hover:bg-blue-500 text-white w-12 h-12 rounded-full flex items-center justify-center disabled:opacity-50 disabled:bg-gray-800 flex-none shadow-lg shadow-blue-900/20 transition-all active:scale-95">
                    <i data-lucide="send" class="w-5 h-5 ml-0.5"></i>
                </button>
            </form>
        </footer>
    </div>

    <script type="module">
        import { CreateMLCEngine } from "https://esm.run/@mlc-ai/web-llm";

        const els = {
            setup: document.getElementById('setup-screen'),
            chat: document.getElementById('chat-interface'),
            btnLoad: document.getElementById('btn-load'),
            modelSelect: document.getElementById('model-select'),
            gpuTag: document.getElementById('gpu-tag'),
            progressArea: document.getElementById('progress-area'),
            progressBar: document.getElementById('progress-bar'),
            progressPercent: document.getElementById('progress-percent'),
            progressLog: document.getElementById('progress-log'),
            progressPhase: document.getElementById('progress-phase'),
            errorMsg: document.getElementById('error-msg'),
            msgs: document.getElementById('messages-container'),
            form: document.getElementById('chat-form'),
            input: document.getElementById('user-input'),
            sendBtn: document.getElementById('send-btn'),
            typing: document.getElementById('typing-indicator')
        };

        lucide.createIcons();
        let engine = null;
        // Mensagens iniciais vazias, mas com system prompt forte
        let messages = [];

        // Auto-resize textarea
        els.input.addEventListener('input', function() {
            this.style.height = '48px';
            this.style.height = (this.scrollHeight) + 'px';
        });

        // 1. Check GPU
        (async () => {
            if (!navigator.gpu) {
                updateGpuTag(false, "WebGPU ausente");
                els.btnLoad.disabled = true;
                return;
            }
            try {
                const adapter = await navigator.gpu.requestAdapter();
                if (!adapter) {
                    updateGpuTag(false, "Erro Adaptador");
                    return;
                }
                const info = adapter.info || { vendor: 'GPU' };
                updateGpuTag(true, `${info.vendor}`);
            } catch (e) {
                updateGpuTag(false, "Erro");
            }
        })();

        function updateGpuTag(success, text) {
            const color = success ? "bg-green-500" : "bg-red-500";
            els.gpuTag.innerHTML = `
                <div class="w-1.5 h-1.5 rounded-full ${color}"></div>
                <span>${text}</span>`;
        }

        // 2. Load Engine
        els.btnLoad.addEventListener('click', async () => {
            const modelId = els.modelSelect.value;
            
            els.btnLoad.classList.add('hidden');
            els.modelSelect.disabled = true;
            els.progressArea.classList.remove('hidden');
            els.errorMsg.classList.add('hidden');

            try {
                const initProgressCallback = (report) => {
                    els.progressPhase.innerText = report.text.split('[')[0].substring(0, 30);
                    els.progressLog.innerText = report.text;
                    if (report.progress) {
                        const p = Math.round(report.progress * 100);
                        els.progressBar.style.width = `${p}%`;
                        els.progressPercent.innerText = `${p}%`;
                    }
                };

                // Carregamos o Llama 3.2 1B com configurações seguras
                engine = await CreateMLCEngine(modelId, { 
                    initProgressCallback,
                    logLevel: "INFO"
                });

                // System Prompt projetado para evitar recusas
                messages = [{ 
                    role: "system", 
                    content: "Você é um assistente prestativo e inteligente. Responda sempre em Português do Brasil. Seja direto." 
                }];

                setTimeout(showChat, 500);

            } catch (err) {
                console.error(err);
                let msg = err.message || "Erro desconhecido";
                
                // Traduções de erros comuns
                if (msg.includes("shader-f16")) msg = "Seu navegador bloqueia recursos rápidos. O modelo f32 (Universal) deveria ter funcionado.";
                if (msg.includes("out of memory") || msg.includes("buffer")) msg = "Memória insuficiente. Feche outras abas e tente novamente.";
                if (msg.includes("Fetch")) msg = "Erro de conexão. Verifique o Wi-Fi.";

                els.errorMsg.classList.remove('hidden');
                els.errorMsg.innerText = msg;
                els.btnLoad.classList.remove('hidden');
                els.progressArea.classList.add('hidden');
            }
        });

        function showChat() {
            els.setup.classList.add('opacity-0', 'pointer-events-none');
            setTimeout(() => els.setup.style.display = 'none', 500);
            els.chat.classList.remove('opacity-0', 'pointer-events-none');
            els.sendBtn.disabled = false;
            
            // Mensagem inicial para testar se o modelo está "são"
            appendMsg('assistant', 'Olá! Sou o Llama 3.2. Estou rodando em modo leve no seu celular. Qual é a sua dúvida?');
        }

        // 3. Chat Logic
        els.form.addEventListener('submit', async (e) => {
            e.preventDefault();
            const text = els.input.value.trim();
            if (!text || !engine) return;

            els.input.style.height = '48px';
            els.input.value = '';
            els.input.blur(); // Fecha teclado no mobile
            
            appendMsg('user', text);
            els.sendBtn.disabled = true;
            els.typing.classList.remove('hidden');
            scrollToBottom();
            
            messages.push({ role: "user", content: text });

            let fullResponse = "";
            const responseDivId = appendMsg('assistant', ''); // Bolha vazia
            const responseTextEl = document.getElementById(responseDivId).querySelector('.content-div');

            try {
                // Configurações para evitar loucura (temperature 0.6) e repetição
                const chunks = await engine.chat.completions.create({
                    messages, 
                    stream: true, 
                    temperature: 0.6,
                    repetition_penalty: 1.05, 
                    max_tokens: 1024
                });

                for await (const chunk of chunks) {
                    const delta = chunk.choices[0]?.delta?.content || "";
                    fullResponse += delta;
                    responseTextEl.innerHTML = formatText(fullResponse); 
                    scrollToBottom();
                }
                messages.push({ role: "assistant", content: fullResponse });
            } catch (err) {
                responseTextEl.innerHTML = `<span class="text-red-400">Erro: ${err.message}</span>`;
            } finally {
                els.sendBtn.disabled = false;
                els.typing.classList.add('hidden');
                scrollToBottom();
            }
        });

        function appendMsg(role, text) {
            const id = 'msg-' + Date.now();
            const div = document.createElement('div');
            const isUser = role === 'user';
            
            div.className = `flex ${isUser ? 'justify-end' : 'justify-start'} w-full`;
            
            const bubbleClass = isUser 
                ? 'bg-blue-600 text-white rounded-2xl rounded-tr-sm shadow-blue-900/20' 
                : 'bg-gray-800 text-gray-200 rounded-2xl rounded-tl-sm border border-gray-700/50 shadow-sm';

            div.innerHTML = `
                <div class="max-w-[85%] px-4 py-3 shadow-lg message-bubble ${bubbleClass}">
                    <div class="content-div text-[15px] leading-relaxed break-words whitespace-pre-wrap">${formatText(text)}</div>
                </div>
            `;
            els.msgs.appendChild(div);
            scrollToBottom();
            return id;
        }

        function formatText(text) {
            if(!text) return '';
            return text
                .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                .replace(/`([^`]+)`/g, '<code class="bg-black/20 px-1 rounded font-mono text-sm">$1</code>');
        }

        function scrollToBottom() {
            // Pequeno delay para garantir renderização
            requestAnimationFrame(() => {
                els.msgs.scrollTop = els.msgs.scrollHeight;
            });
        }
        
        window.addEventListener('resize', scrollToBottom);
    </script>
</body>
</html>


